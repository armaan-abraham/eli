{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output, display\n",
    "from transformers import AutoTokenizer\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "from einops import einsum\n",
    "\n",
    "import eli.train\n",
    "importlib.reload(eli.train)\n",
    "\n",
    "from eli.train.config import encoder_cfg, train_cfg\n",
    "from eli.train.encoder import EncoderDecoder, Encoder, PROMPT_DECODER\n",
    "from eli.train.train import pull_dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def load_encoder_from_s3(s3_key: str, target_path):\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    s3_client.download_file(train_cfg.s3_bucket, s3_key, target_path)\n",
    "    return torch.load(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in environment variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded dataset configuration from s3://eli-datasets/datasets/EleutherAI-pythia-70m-resid_post-4-5-100000000/config.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_cfg = pull_dataset_config(train_cfg)\n",
    "\n",
    "decoder_tokenizer = AutoTokenizer.from_pretrained(train_cfg.decoder_model_name)\n",
    "decoder_tokenizer.pad_token = decoder_tokenizer.eos_token\n",
    "\n",
    "encoder_decoder = EncoderDecoder(decoder_tokenizer, dataset_cfg, encoder_cfg, train_cfg).to(device)\n",
    "\n",
    "encoder = Encoder(dataset_cfg, train_cfg, encoder_cfg).to(device)\n",
    "\n",
    "encoder_path = \"encoder.pt\"\n",
    "# state_dict = load_encoder_from_s3(\"models/EleutherAI-pythia-70m-resid_post-4-5-100000000-pythia-70m-encoder.pt\", encoder_path)\n",
    "state_dict = torch.load(encoder_path)\n",
    "\n",
    "encoder.load_state_dict(state_dict)\n",
    "\n",
    "encoder_decoder.encoder = encoder\n",
    "\n",
    "encoder_decoder = encoder_decoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: pipe: aws s3 cp s3://eli-datasets/datasets/EleutherAI-pythia-70m-resid_post-4-5-100000000/{00000000..00000999}.tar -\n"
     ]
    }
   ],
   "source": [
    "from eli.train.download import download_dataset\n",
    "from eli.train.train import preprocess_acts, preprocess_target_generated_tokens\n",
    "\n",
    "target_tokenizer = AutoTokenizer.from_pretrained(dataset_cfg.target_model_name)\n",
    "target_tokenizer.pad_token = target_tokenizer.eos_token\n",
    "\n",
    "data_loader = iter(download_dataset(dataset_cfg, train_cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print summary stats for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2158238291740417\n"
     ]
    }
   ],
   "source": [
    "num_batches = 20\n",
    "\n",
    "from eli.train.encoder import get_loss\n",
    "\n",
    "losses = []\n",
    "\n",
    "for batch_idx in range(num_batches):\n",
    "    target_acts, target_generated_tokens = next(data_loader)\n",
    "    target_acts = preprocess_acts(target_acts)\n",
    "    target_acts, target_generated_tokens = (\n",
    "        target_acts.to(device),\n",
    "        target_generated_tokens.to(device),\n",
    "    )\n",
    "    target_generated_tokens, attention_mask = (\n",
    "        preprocess_target_generated_tokens(\n",
    "            target_generated_tokens,\n",
    "            target_tokenizer,\n",
    "            decoder_tokenizer,\n",
    "        )\n",
    "    )\n",
    "    losses.append(get_loss(\n",
    "        train_cfg,\n",
    "        device,\n",
    "        encoder_decoder,\n",
    "        target_generated_tokens,\n",
    "        attention_mask,\n",
    "        target_acts,\n",
    "        decoder_tokenizer,\n",
    "        -1,\n",
    "    ).item())\n",
    "\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_acts, target_generated_tokens = next(data_loader)\n",
    "target_acts = preprocess_acts(target_acts)\n",
    "target_acts, target_generated_tokens = (\n",
    "    target_acts.to(device),\n",
    "    target_generated_tokens.to(device),\n",
    ")\n",
    "target_generated_tokens, attention_mask = (\n",
    "    preprocess_target_generated_tokens(\n",
    "        target_generated_tokens,\n",
    "        target_tokenizer,\n",
    "        decoder_tokenizer,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f614a3db2fd44b5780628210f7785a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Next Sample', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ba5fbf667f4a4a859eaa177c8ce37a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from eli.train.encoder import get_target_prediction_loss\n",
    "\n",
    "# Create output widgets for displaying sample information\n",
    "sample_output = widgets.Output()\n",
    "\n",
    "# Create a counter and button\n",
    "current_sample = 0\n",
    "\n",
    "def get_similarities_to_embeddings(\n",
    "    embeddings_seq: Float[Tensor, \"batch tok d_embed\"],\n",
    "    embeddings_vocab: Float[Tensor, \"vocab d_embed\"],\n",
    "    cosine: bool = True,\n",
    ") -> Float[Tensor, \"batch tok vocab\"]:\n",
    "    if cosine:\n",
    "        embeddings_seq_norm = embeddings_seq / embeddings_seq.norm(dim=-1, keepdim=True)\n",
    "        embeddings_vocab_norm = embeddings_vocab / embeddings_vocab.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        return einsum(\n",
    "            embeddings_seq_norm,\n",
    "            embeddings_vocab_norm,\n",
    "            \"batch tok d_embed, vocab d_embed -> batch tok vocab\",\n",
    "        )\n",
    "    else:\n",
    "        embeddings_vocab = embeddings_vocab.unsqueeze(0)\n",
    "        return torch.cdist(embeddings_seq, embeddings_vocab, p=2)\n",
    "\n",
    "\n",
    "def on_button_click(b):\n",
    "    global current_sample\n",
    "    if current_sample < target_generated_tokens.shape[0]:\n",
    "        display_sample(current_sample)\n",
    "        current_sample += 1\n",
    "    else:\n",
    "        with sample_output:\n",
    "            print(\"End of batch reached!\")\n",
    "\n",
    "\n",
    "def create_table(title, headers, rows, col_widths=None):\n",
    "    \"\"\"Helper function to create formatted tables\n",
    "\n",
    "    Args:\n",
    "        title: Table title string\n",
    "        headers: List of header strings\n",
    "        rows: List of rows, where each row is a list of values\n",
    "        col_widths: List of column widths (defaults to 15 for all columns)\n",
    "\n",
    "    Returns:\n",
    "        Formatted table string\n",
    "    \"\"\"\n",
    "    if col_widths is None:\n",
    "        col_widths = [15] * len(headers)\n",
    "\n",
    "    # Ensure first column width accommodates row labels\n",
    "    col_widths[0] = max(col_widths[0], 8)\n",
    "\n",
    "    # Create table string\n",
    "    table = f\"{title}\\n\"\n",
    "\n",
    "    # Create header\n",
    "    header_row = headers[0].ljust(col_widths[0])\n",
    "    for i, header in enumerate(headers[1:], 1):\n",
    "        header_row += header.ljust(col_widths[i])\n",
    "    table += header_row + \"\\n\"\n",
    "\n",
    "    # Add separator\n",
    "    table += \"-\" * len(header_row) + \"\\n\"\n",
    "\n",
    "    # Add rows\n",
    "    for row in rows:\n",
    "        row_str = str(row[0]).ljust(col_widths[0])\n",
    "        for i, cell in enumerate(row[1:], 1):\n",
    "            row_str += str(cell).ljust(col_widths[i])\n",
    "        table += row_str + \"\\n\"\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "losses = []\n",
    "\n",
    "\n",
    "# Function to display a single sample\n",
    "def display_sample(sample_idx):\n",
    "    with torch.no_grad():\n",
    "        # Extract single sample as a \"batch\" of size 1\n",
    "        sample_tokens = target_generated_tokens[sample_idx : sample_idx + 1]\n",
    "        sample_acts = target_acts[sample_idx : sample_idx + 1]\n",
    "        sample_attention_mask = attention_mask[sample_idx : sample_idx + 1]\n",
    "\n",
    "        # Get model outputs for this single sample\n",
    "        (decoder_logits_target, decoder_logits_encoding, virtual_embs) = (\n",
    "            encoder_decoder(\n",
    "                sample_acts, sample_tokens, sample_attention_mask, train_iter=-1\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Calculate loss\n",
    "        pred_loss = get_target_prediction_loss(\n",
    "            decoder_logits_target, sample_tokens, decoder_tokenizer\n",
    "        ).item()\n",
    "        losses.append(pred_loss)\n",
    "\n",
    "        # Get similarities between virtual embeddings and token embeddings of\n",
    "        # decoder\n",
    "        embeddings = encoder_decoder.decoder.get_input_embeddings().weight\n",
    "        similarities = get_similarities_to_embeddings(\n",
    "            virtual_embs, embeddings, cosine=True\n",
    "        )  # [batch tok vocab]\n",
    "\n",
    "        # Get top k tokens by encoder output logits\n",
    "        top_k = 10\n",
    "        top_values, top_indices = torch.topk(\n",
    "            similarities[0], k=top_k, dim=-1\n",
    "        )  # [batch tok]\n",
    "\n",
    "        # Decode tokens for display\n",
    "        sample_decoded = decoder_tokenizer.decode(sample_tokens[0])\n",
    "\n",
    "\n",
    "        # Display results\n",
    "        with sample_output:\n",
    "            sample_output.clear_output(wait=True)\n",
    "            print(f\"Sample {sample_idx + 1}/{target_generated_tokens.shape[0]}\")\n",
    "            print(f\"Target prediction loss: {pred_loss:.6f}\")\n",
    "            print(\"\\nTarget tokens:\")\n",
    "            print(sample_decoded, \"\\n\")\n",
    "\n",
    "            prompt_prefix, prompt_suffix = PROMPT_DECODER.split(\"<thought>\")\n",
    "\n",
    "            print(prompt_prefix)\n",
    "\n",
    "            col_width = 15\n",
    "            headers = [\"Token\"]\n",
    "            for i in range(virtual_embs.shape[1]):\n",
    "                headers.extend([f\"Emb {i}\", f\"Sim {i}\"])\n",
    "\n",
    "            token_rows = []\n",
    "            for k in range(top_k):\n",
    "                row = [f\"Top {k + 1}:\"]\n",
    "                for j in range(virtual_embs.shape[1]):\n",
    "                    token_id = top_indices[j, k].item()\n",
    "                    token_text = decoder_tokenizer.decode([token_id])\n",
    "                    # Replace newlines and tabs for cleaner display\n",
    "                    token_text = token_text.replace(\"\\n\", \"\\\\n\").replace(\n",
    "                        \"\\t\", \"\\\\t\"\n",
    "                    )\n",
    "                    # Truncate to fit in column\n",
    "                    token_display = token_text[: col_width - 2]\n",
    "                    # Add token and similarity as separate columns\n",
    "                    row.append(token_display)\n",
    "                    row.append(f\"{top_values[j, k].item():.3f}\")\n",
    "                token_rows.append(row)\n",
    "\n",
    "            # Create and display the token table\n",
    "            token_table = create_table(\n",
    "                \"\",\n",
    "                headers,\n",
    "                token_rows,\n",
    "                [8]\n",
    "                + [col_width, 8] * virtual_embs.shape[1],  # Adjusted column widths\n",
    "            )\n",
    "            print(token_table)\n",
    "\n",
    "            print(prompt_suffix)\n",
    "\n",
    "            print(sum(losses) / len(losses))\n",
    "\n",
    "\n",
    "# Interactive sample investigation\n",
    "next_button = widgets.Button(description=\"Next Sample\")\n",
    "next_button.on_click(on_button_click)\n",
    "\n",
    "# Show the first sample\n",
    "display_sample(current_sample)\n",
    "\n",
    "display(next_button)\n",
    "display(sample_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
