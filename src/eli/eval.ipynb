{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output, display\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import importlib\n",
    "\n",
    "import eli.encoder\n",
    "\n",
    "importlib.reload(eli.encoder)\n",
    "from eli.config import cfg, encoder_cfg\n",
    "from eli.encoder import (\n",
    "    PROMPT_PREFIX,\n",
    "    PROMPT_SUFFIX,\n",
    "    Encoder,\n",
    "    EncoderDecoder,\n",
    "    EncoderTrainer,\n",
    "    calculate_dinalar_loss,\n",
    "    get_embeddings_from_decoder,\n",
    "    kl_div,\n",
    "    calculate_target_prediction_loss,\n",
    ")\n",
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load encoder and decoder\n",
    "\n",
    "cfg.buffer_size_samples = cfg.target_model_batch_size_samples = cfg.train_batch_size_samples\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.decoder_model_name)\n",
    "\n",
    "encoder_decoder = EncoderDecoder(cfg, encoder_cfg, tokenizer).to(cfg.device)\n",
    "\n",
    "encoder = Encoder(cfg, encoder_cfg).to(cfg.device)\n",
    "\n",
    "encoder_path = \"encoder-dec-16-enc-4-pythia-31m.pt\"\n",
    "encoder.load_state_dict(torch.load(encoder_path))\n",
    "\n",
    "encoder_decoder.encoder = encoder\n",
    "\n",
    "encoder_decoder = encoder_decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(cfg.target_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data collector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:target_generated_tokens size: 16384 bytes (0.02 MB)\n",
      "INFO:root:target_acts size: 262144 bytes (0.25 MB)\n",
      "INFO:root:input_tokens size: 65536 bytes (0.06 MB)\n",
      "INFO:root:Total shared memory size: 0.00 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19632deaa2e94fe3bdc0df1b21478c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f5034c1dfc44f9aaec394b60f27829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Tokenize and concatenate called\n",
      "INFO:root:Full text length: 43727350\n",
      "INFO:root:Num tokens: 9672977\n",
      "/root/eli/.venv/lib/python3.12/site-packages/datasets/formatting/torch_formatter.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(value, **{**default_dtype, **self.torch_tensor_kwargs})\n",
      "INFO:root:Processing data directly on cuda without workers\n",
      "INFO:root:Processing chunk 0:256 on cuda\n",
      "INFO:root:Processing batch 0:256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-31m into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:CHUNK 0:256 COMPLETED, Max GPU memory allocated: 2.24 GB, Max GPU memory reserved: 2.52 GB\n",
      "INFO:root:Direct data processing completed\n"
     ]
    }
   ],
   "source": [
    "# Load eval data\n",
    "\n",
    "from eli.data import DataCollector\n",
    "\n",
    "cfg.use_data_collector_workers = False\n",
    "\n",
    "print(\"Initializing data collector\")\n",
    "data_collector = DataCollector(cfg)\n",
    "\n",
    "print(\"Collecting data\")\n",
    "data_collector.collect_data()\n",
    "\n",
    "data = data_collector.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target prediction loss: 3.610379219055176\n",
      "Dinalar loss: 5.70062255859375\n"
     ]
    }
   ],
   "source": [
    "# Print loss statistics\n",
    "target_generated_tokens = data[\"target_generated_tokens\"]\n",
    "target_acts = data[\"target_acts\"]\n",
    "\n",
    "buffer_size = target_acts.shape[0]\n",
    "batch_size = cfg.train_batch_size_samples\n",
    "num_batches = buffer_size // batch_size\n",
    "\n",
    "target_prediction_losses = []\n",
    "dinalar_losses = []\n",
    "\n",
    "for batch_idx in range(num_batches):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "\n",
    "    # Extract batch data and move to device\n",
    "    batch_tokens = target_generated_tokens[start_idx:end_idx].to(cfg.device)\n",
    "    batch_acts = target_acts[start_idx:end_idx].to(cfg.device)\n",
    "\n",
    "    loss, target_prediction_loss, dinalar_loss, encoder_output_logits = EncoderTrainer.loss(\n",
    "        cfg, encoder_decoder, batch_tokens, batch_acts, -1\n",
    "    )\n",
    "\n",
    "    target_prediction_losses.append(target_prediction_loss.item())\n",
    "    dinalar_losses.append(dinalar_loss.item())\n",
    "\n",
    "print(f\"Target prediction loss: {np.mean(target_prediction_losses)}\")\n",
    "print(f\"Dinalar loss: {np.mean(dinalar_losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a03eee77c2342b993fb6f19a151f779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27c6e51e2444e83a5469b760bd12a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187,  5453, 43472],\n",
      "        [41768,  6123,     3],\n",
      "        [   13, 40125, 43327],\n",
      "        [41972,   247,    15]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 24239,  1947],\n",
      "        [15436,   253, 30696],\n",
      "        [   13,   669, 13858],\n",
      "        [  253, 30611, 48763]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 14457,  5453],\n",
      "        [  253, 22778, 30081],\n",
      "        [15032,  1058,  9436],\n",
      "        [13826,   253, 36634]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187,  3182,  4144],\n",
      "        [  253, 24645,  6123],\n",
      "        [16372, 15739,    13],\n",
      "        [35135, 28076,  8772]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 48278,  5453],\n",
      "        [40394,   273, 20585],\n",
      "        [ 9646, 43648, 29626],\n",
      "        [ 8772, 33721, 15699]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 36314, 14457],\n",
      "        [  253, 30081, 26582],\n",
      "        [ 5862,    13,  1769],\n",
      "        [  253, 28076,   285]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187,  5429,  7442],\n",
      "        [45597,  2737, 16770],\n",
      "        [   13,  5862, 43648],\n",
      "        [28076,  8675, 33721]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 18786, 24239],\n",
      "        [  253, 27989, 41768],\n",
      "        [ 2467,   187,    13],\n",
      "        [13826,   253, 37610]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 41453, 14457],\n",
      "        [  253, 45597, 44680],\n",
      "        [20432, 41791,  1769],\n",
      "        [47312,   253,  8772]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187,  8798, 44576],\n",
      "        [    3, 23929,  8740],\n",
      "        [   13, 43648,  4485],\n",
      "        [48315,   253,  8675]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 16602, 38803],\n",
      "        [22367,   253,  6045],\n",
      "        [48818,  5862,   273],\n",
      "        [49871,  8675, 30543]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 36430,    93],\n",
      "        [  253,     3,   422],\n",
      "        [14750,   147, 22760],\n",
      "        [33721,   253, 45614]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[31086,   187,  8834],\n",
      "        [  253, 30081, 20585],\n",
      "        [18563,  4738, 46880],\n",
      "        [27094, 21938, 47632]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[40229,   187, 47449],\n",
      "        [ 6123,    13,  6435],\n",
      "        [   13, 39146, 16372],\n",
      "        [13826, 12619, 12667]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 47449, 22322],\n",
      "        [  253, 30081, 45597],\n",
      "        [40125, 27227,  1191],\n",
      "        [ 8675, 33721, 48524]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 44576, 15677],\n",
      "        [    3, 23929,   253],\n",
      "        [   13,  5862,  8710],\n",
      "        [  253,  8772, 47632]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[46603,   877,   187],\n",
      "        [  253,     3, 34091],\n",
      "        [40125,   187, 32250],\n",
      "        [ 7463, 47632,  8675]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 19527, 21979],\n",
      "        [23588,   253, 45528],\n",
      "        [40125,  1946, 14750],\n",
      "        [22934, 47632, 26036]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 41453, 38772],\n",
      "        [  253,  6123,     3],\n",
      "        [20516, 41791,  2196],\n",
      "        [ 4591, 33721, 13826]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[46134,   187,  7442],\n",
      "        [30598, 25438, 49300],\n",
      "        [ 4485,   669,  5862],\n",
      "        [28076, 11764, 17060]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 47449, 28192],\n",
      "        [  253, 26582, 27787],\n",
      "        [ 4485, 14750,    15],\n",
      "        [  253, 37610, 23105]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 47449, 26092],\n",
      "        [  253,     3,  5055],\n",
      "        [ 4485,    13, 37681],\n",
      "        [34463, 36500, 28076]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187,  4928, 28059],\n",
      "        [  253, 25731, 41768],\n",
      "        [   13, 48818, 13156],\n",
      "        [20615,   253, 13826]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 45268, 14457],\n",
      "        [  273, 30081, 32242],\n",
      "        [10714,   273, 37681],\n",
      "        [ 6985,   253, 48315]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[47449,   187, 48919],\n",
      "        [30640,     3, 45685],\n",
      "        [ 4485,   147,   669],\n",
      "        [ 6985,  8675, 13826]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 25634, 24239],\n",
      "        [ 9427,     3,   253],\n",
      "        [37918, 44988, 43997],\n",
      "        [15934, 22934, 23641]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[23091,   187,  8822],\n",
      "        [30081, 18736,   273],\n",
      "        [21578,    13,  4738],\n",
      "        [30543, 30115, 37234]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 18994,  3719],\n",
      "        [   13,   253,     3],\n",
      "        [   13,  4485, 16321],\n",
      "        [ 4477, 40973,   253]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187,  8822, 14457],\n",
      "        [15446, 44680, 14466],\n",
      "        [  273, 29336,    13],\n",
      "        [37610, 24372, 28076]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 46603, 45268],\n",
      "        [  253, 49349,   398],\n",
      "        [41791, 49853,  4485],\n",
      "        [42010,  1311, 48315]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 28086,  8834],\n",
      "        [    3, 47172,   253],\n",
      "        [20031,   273,  5862],\n",
      "        [26735, 23844, 12882]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 43472, 47449],\n",
      "        [    3, 25731,    13],\n",
      "        [ 4485,   669,   147],\n",
      "        [37610,   253, 34818]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 17732,  8822],\n",
      "        [ 2390, 18626, 21733],\n",
      "        [40125, 22760,   273],\n",
      "        [  253, 23844, 45614]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 36430,  3001],\n",
      "        [ 1040, 12992,  6045],\n",
      "        [ 4485,    13, 42664],\n",
      "        [37610, 32073, 45614]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[25330, 13983, 34412],\n",
      "        [  185, 24261, 49610],\n",
      "        [ 4485, 29336, 37866],\n",
      "        [27154, 49871,  4444]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[20002, 43909,   187],\n",
      "        [23641,   175,  6045],\n",
      "        [44469, 29628,  4485],\n",
      "        [32401, 40401, 26935]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[ 9327,   187,  2099],\n",
      "        [  253, 48765, 26582],\n",
      "        [17341,    13,  4485],\n",
      "        [  253, 23844, 48315]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 21458, 16447],\n",
      "        [30598, 26582,     3],\n",
      "        [   13,   187, 49826],\n",
      "        [23844, 14160,  7333]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 33301, 45268],\n",
      "        [47172, 11616, 26582],\n",
      "        [ 8186,    13,  1769],\n",
      "        [23844, 14160,  1289]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 47449, 48919],\n",
      "        [37874, 40394, 31165],\n",
      "        [40125,  4485,  4738],\n",
      "        [  253,  8675, 44771]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 47449, 48919],\n",
      "        [    3,    13,   253],\n",
      "        [40125, 10032, 33047],\n",
      "        [13826,  1289, 37610]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 14457, 24239],\n",
      "        [20585, 17992,   253],\n",
      "        [37969, 13430, 45000],\n",
      "        [  253,  8675, 39407]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[46603,   187, 47449],\n",
      "        [45295, 38218, 47016],\n",
      "        [   13, 49414, 37681],\n",
      "        [37610, 12448, 40401]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[20002,  7442, 22685],\n",
      "        [30216, 28086,   253],\n",
      "        [48818, 33820, 20712],\n",
      "        [49717,  6427,  7629]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 14457, 50143],\n",
      "        [ 3481, 30081,   653],\n",
      "        [28035, 47279,  4485],\n",
      "        [49717,  6985,   253]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 40791, 31979],\n",
      "        [  253, 30081,  7183],\n",
      "        [30941, 26437,  2501],\n",
      "        [ 7463, 48128,   253]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[31569,   187, 17732],\n",
      "        [  253,  7678, 25191],\n",
      "        [42565, 32056,  4485],\n",
      "        [49717, 40401, 18972]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187,  8834,  3182],\n",
      "        [  253,  6123,  5939],\n",
      "        [21273,  2399,  1939],\n",
      "        [ 7463, 48128, 39936]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n",
      "encoder_output_logits.shape torch.Size([1, 4, 50304])\n",
      "tensor([[  187, 45273, 36796],\n",
      "        [23233,  6045, 25130],\n",
      "        [40125, 38007, 13156],\n",
      "        [ 8962,   253,  7463]], device='cuda:0')\n",
      "torch.Size([4, 3])\n",
      "top_values.shape torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# Create output widgets for displaying sample information\n",
    "sample_output = widgets.Output()\n",
    "button_output = widgets.Output()\n",
    "\n",
    "# Create a counter and button\n",
    "current_sample = 0\n",
    "\n",
    "\n",
    "def on_button_click(b):\n",
    "    global current_sample\n",
    "    if current_sample < batch_size:\n",
    "        display_sample(current_sample)\n",
    "        current_sample += 1\n",
    "    else:\n",
    "        with sample_output:\n",
    "            print(\"End of batch reached!\")\n",
    "\n",
    "\n",
    "def create_table(title, headers, rows, col_widths=None):\n",
    "    \"\"\"Helper function to create formatted tables\n",
    "\n",
    "    Args:\n",
    "        title: Table title string\n",
    "        headers: List of header strings\n",
    "        rows: List of rows, where each row is a list of values\n",
    "        col_widths: List of column widths (defaults to 15 for all columns)\n",
    "\n",
    "    Returns:\n",
    "        Formatted table string\n",
    "    \"\"\"\n",
    "    if col_widths is None:\n",
    "        col_widths = [15] * len(headers)\n",
    "\n",
    "    # Ensure first column width accommodates row labels\n",
    "    col_widths[0] = max(col_widths[0], 8)\n",
    "\n",
    "    # Create table string\n",
    "    table = f\"{title}\\n\"\n",
    "\n",
    "    # Create header\n",
    "    header_row = headers[0].ljust(col_widths[0])\n",
    "    for i, header in enumerate(headers[1:], 1):\n",
    "        header_row += header.ljust(col_widths[i])\n",
    "    table += header_row + \"\\n\"\n",
    "\n",
    "    # Add separator\n",
    "    table += \"-\" * len(header_row) + \"\\n\"\n",
    "\n",
    "    # Add rows\n",
    "    for row in rows:\n",
    "        row_str = str(row[0]).ljust(col_widths[0])\n",
    "        for i, cell in enumerate(row[1:], 1):\n",
    "            row_str += str(cell).ljust(col_widths[i])\n",
    "        table += row_str + \"\\n\"\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "# Function to display a single sample\n",
    "def display_sample(sample_idx):\n",
    "    with torch.no_grad():\n",
    "        with torch.autocast(device_type=cfg.device.type, dtype=cfg.dtype):\n",
    "            # Extract single sample as a \"batch\" of size 1\n",
    "            sample_tokens = target_generated_tokens[sample_idx : sample_idx + 1].to(\n",
    "                cfg.device\n",
    "            )\n",
    "            sample_acts = target_acts[sample_idx : sample_idx + 1].to(cfg.device)\n",
    "\n",
    "            encoder = encoder_decoder.encoder\n",
    "            encoder_output_logits = encoder(sample_acts) # [batch tok vocab]\n",
    "\n",
    "            # Convert logits to one-hot-like by making the max value very large and others small\n",
    "            # max_values, max_indices = torch.max(encoder_output_logits, dim=-1, keepdim=True)\n",
    "            # one_hot_logits = torch.ones_like(encoder_output_logits) * -100.0  # Set all values to a small number\n",
    "            # one_hot_logits.scatter_(dim=-1, index=max_indices, value=100.0)   # Set max values to a large number\n",
    "            # encoder_output_logits = one_hot_logits\n",
    "\n",
    "            # Get model outputs for this single sample\n",
    "            (decoder_logits_target, decoder_logits_encoding, virtual_embs, encoder_output_logits) = (\n",
    "                encoder_decoder(sample_acts, sample_tokens, encoder_output_logits=encoder_output_logits, train_iter=-1)\n",
    "            )\n",
    "\n",
    "            # Calculate losses using existing functions\n",
    "            pred_loss = calculate_target_prediction_loss(decoder_logits_target, sample_tokens).item()\n",
    "            din_loss = calculate_dinalar_loss(\n",
    "                decoder_logits_encoding,\n",
    "                encoder_output_logits,\n",
    "            ).item()\n",
    "\n",
    "\n",
    "            print(\"encoder_output_logits.shape\", encoder_output_logits.shape)\n",
    "\n",
    "            encoder_output_probs = torch.nn.functional.softmax(encoder_output_logits, dim=-1)\n",
    "\n",
    "            # Get top 3 tokens by encoder output logits\n",
    "            top_k = 3\n",
    "            top_values, top_indices = torch.topk(\n",
    "                encoder_output_probs[0], k=top_k, dim=-1\n",
    "            )  # [batch tok]\n",
    "\n",
    "            print(top_indices)\n",
    "            print(top_indices.shape)\n",
    "\n",
    "            print(\"top_values.shape\", top_values.shape)\n",
    "\n",
    "            # Decode tokens for display\n",
    "            sample_decoded = tokenizer.decode(sample_tokens[0])\n",
    "\n",
    "            # Display results\n",
    "            with sample_output:\n",
    "                sample_output.clear_output(wait=True)\n",
    "                print(f\"Sample {sample_idx+1}/{batch_size}\")\n",
    "                print(f\"Target prediction loss: {pred_loss:.6f}\")\n",
    "                print(f\"Dinalar loss: {din_loss:.6f}\")\n",
    "                print(\"\\nTarget tokens:\")\n",
    "                print(sample_decoded, \"\\n\")\n",
    "\n",
    "                # Also decode and display the prefix and suffix tokens\n",
    "                prefix_tokens = tokenizer(PROMPT_PREFIX, return_tensors=\"pt\").input_ids[\n",
    "                    0\n",
    "                ]\n",
    "                suffix_tokens = tokenizer(PROMPT_SUFFIX, return_tensors=\"pt\").input_ids[\n",
    "                    0\n",
    "                ]\n",
    "\n",
    "                print(tokenizer.decode(prefix_tokens))\n",
    "\n",
    "                # Prepare data for the tokens table\n",
    "                col_width = 15\n",
    "                headers = [\"Token\"] + [f\"Emb {i}\" for i in range(virtual_embs.shape[1])]\n",
    "\n",
    "                token_rows = []\n",
    "                for k in range(top_k):\n",
    "                    row = [f\"Top {k+1}:\"]\n",
    "                    for j in range(virtual_embs.shape[1]):\n",
    "                        token_id = top_indices[j, k].item()\n",
    "                        token_text = tokenizer.decode([token_id])\n",
    "                        # Replace newlines and tabs for cleaner display\n",
    "                        token_text = token_text.replace(\"\\n\", \"\\\\n\").replace(\n",
    "                            \"\\t\", \"\\\\t\"\n",
    "                        )\n",
    "                        # Truncate to fit in column\n",
    "                        token_display = token_text[: col_width - 2]\n",
    "                        row.append(token_display)\n",
    "                    token_rows.append(row)\n",
    "\n",
    "                # Create and display the token table\n",
    "                token_table = create_table(\n",
    "                    \"\", headers, token_rows, [8] + [col_width] * virtual_embs.shape[1]\n",
    "                )\n",
    "                print(token_table)\n",
    "\n",
    "                # Create table for logit values\n",
    "                logit_rows = []\n",
    "                for k in range(top_k):\n",
    "                    row = [f\"Top {k+1}:\"]\n",
    "                    for j in range(virtual_embs.shape[1]):\n",
    "                        # Format logit value with 5 decimal places\n",
    "                        prob = top_values[j, k].item()\n",
    "                        row.append(f\"{prob:.5f}\")\n",
    "                    logit_rows.append(row)\n",
    "\n",
    "                # Create and display the logits table\n",
    "                logit_table = create_table(\n",
    "                    \"Logit Values:\",\n",
    "                    headers,\n",
    "                    logit_rows,\n",
    "                    [8] + [col_width] * virtual_embs.shape[1],\n",
    "                )\n",
    "                print(logit_table)\n",
    "\n",
    "                print(tokenizer.decode(suffix_tokens))\n",
    "\n",
    "\n",
    "# Interactive sample investigation\n",
    "next_button = widgets.Button(description=\"Next Sample\")\n",
    "next_button.on_click(on_button_click)\n",
    "\n",
    "# Display the button and sample output in separate areas\n",
    "with button_output:\n",
    "    display(next_button)\n",
    "display(button_output)\n",
    "display(sample_output)\n",
    "\n",
    "# Show the first sample\n",
    "if batch_size > 0:\n",
    "    display_sample(current_sample)\n",
    "    current_sample += 1\n",
    "else:\n",
    "    with sample_output:\n",
    "        print(\"No samples in batch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
