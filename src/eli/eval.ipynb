{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output, display\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import eli.encoder\n",
    "\n",
    "importlib.reload(eli.encoder)\n",
    "from einops import einsum\n",
    "\n",
    "from eli.config import cfg, encoder_cfg\n",
    "from eli.encoder import (\n",
    "    PROMPT_DECODER,\n",
    "    Encoder,\n",
    "    EncoderDecoder,\n",
    "    EncoderTrainer,\n",
    "    calculate_target_prediction_loss,\n",
    "    get_embeddings_from_decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load encoder and decoder\n",
    "cfg.buffer_size_samples = cfg.target_model_batch_size_samples = (\n",
    "    cfg.train_batch_size_samples\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.decoder_model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "encoder_decoder = EncoderDecoder(cfg, encoder_cfg, tokenizer).to(cfg.device)\n",
    "\n",
    "encoder = Encoder(cfg, encoder_cfg).to(cfg.device)\n",
    "\n",
    "encoder_path = \"saved_models/encoder.pt\"\n",
    "encoder.load_state_dict(torch.load(encoder_path))\n",
    "\n",
    "encoder_decoder.encoder = encoder\n",
    "\n",
    "encoder_decoder = encoder_decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(cfg.target_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data collector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:target_generated_tokens size: 1024 bytes (0.00 MB)\n",
      "INFO:root:target_acts size: 786432 bytes (0.75 MB)\n",
      "INFO:root:input_tokens size: 65536 bytes (0.06 MB)\n",
      "INFO:root:Total shared memory size: 0.00 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101b6f1129a44210b031fceb12d16640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bd097cfb484d8c93d7c714e06a42b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Tokenize and concatenate called\n",
      "INFO:root:Full text length: 43727350\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (488415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "INFO:root:Num tokens: 9655191\n",
      "/root/eli/.venv/lib/python3.12/site-packages/datasets/formatting/torch_formatter.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(value, **{**default_dtype, **self.torch_tensor_kwargs})\n",
      "INFO:root:Processing data directly on cuda without workers\n",
      "INFO:root:Processing chunk 0:256 on cuda\n",
      "INFO:root:Processing batch 0:256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Direct data processing completed\n"
     ]
    }
   ],
   "source": [
    "# Load eval data\n",
    "\n",
    "from eli.data import DataCollector\n",
    "\n",
    "cfg.use_data_collector_workers = False\n",
    "\n",
    "print(\"Initializing data collector\")\n",
    "data_collector = DataCollector(cfg)\n",
    "\n",
    "print(\"Collecting data\")\n",
    "data_collector.collect_data()\n",
    "\n",
    "data = data_collector.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 4]) torch.Size([256, 4])\n",
      "Target prediction loss: 3.678266763687134\n"
     ]
    }
   ],
   "source": [
    "# Print loss statistics\n",
    "target_generated_tokens = data[\"target_generated_tokens\"]\n",
    "target_acts = data[\"target_acts\"]\n",
    "\n",
    "buffer_size = target_acts.shape[0]\n",
    "batch_size = cfg.train_batch_size_samples\n",
    "num_batches = buffer_size // batch_size\n",
    "\n",
    "target_prediction_losses = []\n",
    "dinalar_losses = []\n",
    "\n",
    "def recode_and_strip(tokens, tokenizer):\n",
    "    decoded = tokenizer.batch_decode(\n",
    "        sequences=tokens,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=True,\n",
    "    )\n",
    "    decoded = [r.strip() for r in decoded]\n",
    "    encoded = tokenizer(\n",
    "        decoded, add_special_tokens=False, return_tensors=\"pt\", padding=True\n",
    "    )\n",
    "    output_tokens = encoded.input_ids.long()\n",
    "    attention_mask = encoded.attention_mask\n",
    "    return output_tokens, attention_mask\n",
    "\n",
    "for batch_idx in range(num_batches):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "\n",
    "    # Extract batch data and move to device\n",
    "    batch_tokens = target_generated_tokens[start_idx:end_idx].to(cfg.device)\n",
    "    batch_acts = target_acts[start_idx:end_idx].to(cfg.device)\n",
    "\n",
    "    batch_tokens, attention_mask = recode_and_strip(batch_tokens, tokenizer)\n",
    "    batch_tokens = batch_tokens.to(cfg.device)\n",
    "\n",
    "    print(batch_tokens.shape, attention_mask.shape)\n",
    "\n",
    "    attention_mask = attention_mask.to(cfg.device)\n",
    "\n",
    "    loss = EncoderTrainer.loss(\n",
    "        cfg, encoder_decoder, batch_tokens, attention_mask, batch_acts, tokenizer, train_iter=-1\n",
    "    )\n",
    "    target_prediction_losses.append(loss.item())\n",
    "\n",
    "print(f\"Target prediction loss: {np.mean(target_prediction_losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428d7fb1e67b4f909721872d1e4b0d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e925d33d054aeeb24154114dfae961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3812,  7936,  2592,   981, 21977, 45405, 50256,  2443, 18537, 46751]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   12,  3812, 18537, 18667,  3318,  2832, 16159, 31173,  2524, 46852]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[  12,   14,  284,  290, 3812,   11, 2190,  287,  832, 5527]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[   12,  2524,   620,  8033,  6504, 48466, 19183,    14,   598, 50256]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[ 284, 3812,   12,  290, 4058,   11,  416,  287,  832, 1377]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[   12,  8225, 16469,  4058,    14,  2524,  5527,  3812, 10371, 41961]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[   12,  4058, 30387,    14,  6028,    11, 40112,   290, 21111,  8225]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[ 3816,   303, 17551,  4885,  4058, 20190, 19483, 15164,  9323,  1158]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[ 3812,   832,    12,  3967, 30387,  4058, 17319,   656,    14,  1377]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[18537,   905,   981,  3017, 21949,    12,   330,  6028,  4914,  2291]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[   12,  4058,    14,  3967,   284,   620,   286, 50256, 21111,   562]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[17319,  1781, 41961, 15727,  2524, 15779,  6504,   670,   319,    14]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[ 416,  832, 4058,   12,  287,  319,  290,   11, 3812,   14]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[30387,    12,  3812,    11, 26358,   562, 21111, 20521,   981, 31533]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[ 3812, 20521,  3967, 41961, 45405,   832,   656,   562,  6504,  7848]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[  832,   319,   284,  4058,   416,   290,  3812,   287, 22020,   656]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[4058,   12, 3812,   14,  284,  286, 9521,   11,  290,   13]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[ 3812,   866,  3318,   620, 15727,    12,  3967,   284, 29033,   290]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[   12,  3967,   832,   284, 39639,    11,   290,   286,   416,   620]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[  12,   13,  290,   11,   14, 3967,  284, 1222,  620,  287]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[   12, 21949, 20521, 21111,  3812,  1377, 31533, 28112,  2524,  2592]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[ 2592,  3812, 17319,  6504,   319,  1087,   284,  2524,  1781, 41961]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[38568,  6504,  2524,  3812, 45405,  2592, 21111, 36129, 22111, 25498]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[  286,   832,   284,  7087,    12, 20521,  5527, 21111,  3372, 16561]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[ 2524,    12, 23707,   284, 41961, 17732, 18537,   562, 21949,   620]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[  832,  6504, 48466, 45405, 21156,  3812,  7093, 21111,  4291,  2443]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[45405, 21111, 48466,   430,   832, 24398, 19950, 43911,  8875, 43957]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[45405, 20521,   832,   620, 18409,  6504,  8763,  2524,  1755,   319]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[ 3812, 38454, 48466,  6504, 15727,    12,   284, 20521, 40112,  2190]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[  620, 20062,  2190, 18537,  6504, 17732, 16561,  6463, 38454,   905]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[   14,    12,  5527, 43957,    11, 25717,   284, 16561,   584,  6504]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[  284,  3812,    12,   416, 24398, 15727, 20543, 11139, 16561, 43957]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[   12,    14,   832,   286,    11,   329,   584, 19950,   284,   379]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[   12,   832,   290,   620,   286,    11,  3716, 16561,  3407,  3812]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[ 2524, 48466, 20521,   562,    12,  5527, 21111,  2592, 16469, 43957]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[   11,   284,  6504, 47528,  3812,  2524,    13,    14,   981,  2592]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[   12,    14, 19950,   620,  6504,  2592,  5527,   284,  8225, 41961]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[   12,    11, 28112, 12214, 30387, 18537, 21977, 48466, 18631,  1302]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[ 9009,  9521,   620, 18537,    14,  6504,  2689,   628,  6076, 41294]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[   12,  6504, 19950, 38454,    14,   620,   284, 30387, 48466, 16561]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[ 6504,   832, 48466,   416, 44480, 16823,  5527,   620, 21156, 38454]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[  832,   416,  3812,    14,    11,   319, 48466,  1909,   290,    13]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[41961,  9009, 18537,  2524, 47528, 20521,    12, 30387,   284,    11]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[30387, 18537, 45405, 21111, 16469, 20521,    12,  7936,  8225,  3812]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[   12,  3017,    14, 18537, 16561,  5281,  9816,    11, 10651, 50256]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[  832,  3812,   284,   656,  6504, 15727,  4058, 41961,   319, 30387]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[ 2524, 16561,  3052,  3407, 48466,  6504,    12,  6701, 18537,   905]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[24398,   430,   785,    12,  1429,  7596, 48261,  4188, 10178, 20543]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[   12,    14,  3967,  6504, 45405, 16561,   562, 20521,  3812,  8875]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[16561, 16823, 24398,    14,  3812,   832,    12,   284, 21156,  6504]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[  430,    12,   832, 24398,  3812,    14, 45405, 31173, 20521, 16561]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[   12,   286, 24398,  3812, 21111,   430,   832,    14,   284, 16561]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n",
      "tensor([[16823, 16561,    14,  3017, 17831,  3407, 45405, 24398,    12,  3812]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "top_values.shape torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "\n",
    "# Create output widgets for displaying sample information\n",
    "sample_output = widgets.Output()\n",
    "button_output = widgets.Output()\n",
    "\n",
    "# Create a counter and button\n",
    "current_sample = 0\n",
    "\n",
    "def get_similarities_to_embeddings(\n",
    "    embeddings: Float[Tensor, \"batch tok d_embed\"],\n",
    "    target_embeddings: Float[Tensor, \"vocab d_embed\"],\n",
    ") -> Float[Tensor, \"batch tok vocab\"]:\n",
    "    \"\"\"Computes the cosine similarity between each token embedding and each target embedding.\"\"\"\n",
    "    # embeddings shape: [batch, tok, d_embed]\n",
    "    # target_embeddings shape: [vocab, d_embed]\n",
    "\n",
    "    # Reshape embeddings to [batch*tok, d_embed]\n",
    "    batch_size, seq_len, d_embed = embeddings.shape\n",
    "\n",
    "    target_embeddings_norm = target_embeddings / target_embeddings.norm(dim=-1, keepdim=True)\n",
    "    embeddings_norm = embeddings / embeddings.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    return einsum(embeddings_norm, target_embeddings_norm, \"batch tok d_embed, vocab d_embed -> batch tok vocab\")\n",
    "\n",
    "\n",
    "def on_button_click(b):\n",
    "    global current_sample\n",
    "    if current_sample < batch_size:\n",
    "        display_sample(current_sample)\n",
    "        current_sample += 1\n",
    "    else:\n",
    "        with sample_output:\n",
    "            print(\"End of batch reached!\")\n",
    "\n",
    "\n",
    "def create_table(title, headers, rows, col_widths=None):\n",
    "    \"\"\"Helper function to create formatted tables\n",
    "\n",
    "    Args:\n",
    "        title: Table title string\n",
    "        headers: List of header strings\n",
    "        rows: List of rows, where each row is a list of values\n",
    "        col_widths: List of column widths (defaults to 15 for all columns)\n",
    "\n",
    "    Returns:\n",
    "        Formatted table string\n",
    "    \"\"\"\n",
    "    if col_widths is None:\n",
    "        col_widths = [15] * len(headers)\n",
    "\n",
    "    # Ensure first column width accommodates row labels\n",
    "    col_widths[0] = max(col_widths[0], 8)\n",
    "\n",
    "    # Create table string\n",
    "    table = f\"{title}\\n\"\n",
    "\n",
    "    # Create header\n",
    "    header_row = headers[0].ljust(col_widths[0])\n",
    "    for i, header in enumerate(headers[1:], 1):\n",
    "        header_row += header.ljust(col_widths[i])\n",
    "    table += header_row + \"\\n\"\n",
    "\n",
    "    # Add separator\n",
    "    table += \"-\" * len(header_row) + \"\\n\"\n",
    "\n",
    "    # Add rows\n",
    "    for row in rows:\n",
    "        row_str = str(row[0]).ljust(col_widths[0])\n",
    "        for i, cell in enumerate(row[1:], 1):\n",
    "            row_str += str(cell).ljust(col_widths[i])\n",
    "        table += row_str + \"\\n\"\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "def shuffle_data(tokens, acts, seed=None):\n",
    "    \"\"\"\n",
    "    Shuffle the tokens and acts tensors in the same order.\n",
    "\n",
    "    Args:\n",
    "        tokens: Tensor of token IDs\n",
    "        acts: Tensor of activations\n",
    "        seed: Optional random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (shuffled_tokens, shuffled_acts)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    # Get the number of samples\n",
    "    num_samples = tokens.size(0)\n",
    "\n",
    "    # Generate random permutation indices\n",
    "    indices = torch.randperm(num_samples)\n",
    "\n",
    "    # Shuffle both tensors using the same indices\n",
    "    shuffled_tokens = tokens[indices]\n",
    "    shuffled_acts = acts[indices]\n",
    "\n",
    "    return shuffled_tokens, shuffled_acts\n",
    "\n",
    "losses = []\n",
    "\n",
    "# Function to display a single sample\n",
    "def display_sample(sample_idx):\n",
    "    with torch.no_grad():\n",
    "        with torch.autocast(device_type=cfg.device.type, dtype=cfg.dtype):\n",
    "            # Extract single sample as a \"batch\" of size 1\n",
    "            sample_tokens = target_generated_tokens[sample_idx : sample_idx + 1].to(\n",
    "                cfg.device, dtype=torch.long\n",
    "            )\n",
    "            sample_tokens, attention_mask = recode_and_strip(sample_tokens, tokenizer)\n",
    "            sample_tokens = sample_tokens.to(cfg.device)\n",
    "            attention_mask = attention_mask.to(cfg.device)\n",
    "            sample_acts = target_acts[sample_idx : sample_idx + 1].to(cfg.device)\n",
    "\n",
    "            # encoder = encoder_decoder.encoder\n",
    "            # encoder_output_logits = encoder(sample_acts) # [batch tok vocab]\n",
    "\n",
    "            # Convert logits to one-hot-like by making the max value very large and others small\n",
    "            # max_values, max_indices = torch.max(encoder_output_logits, dim=-1, keepdim=True)\n",
    "            # one_hot_logits = torch.ones_like(encoder_output_logits) * -100.0  # Set all values to a small number\n",
    "            # one_hot_logits.scatter_(dim=-1, index=max_indices, value=100.0)   # Set max values to a large number\n",
    "            # encoder_output_logits = one_hot_logits\n",
    "\n",
    "            # Get model outputs for this single sample\n",
    "            (decoder_logits_target, decoder_logits_encoding, virtual_embs) = (\n",
    "                encoder_decoder(sample_acts, sample_tokens, attention_mask, train_iter=-1)\n",
    "            )\n",
    "\n",
    "            # Calculate losses using existing functions\n",
    "            pred_loss = calculate_target_prediction_loss(\n",
    "                decoder_logits_target, sample_tokens, tokenizer\n",
    "            ).item()\n",
    "            losses.append(pred_loss)\n",
    "            # din_loss = calculate_dinalar_loss(\n",
    "            #     decoder_logits_encoding,\n",
    "            #     encoder_output_logits,\n",
    "            # ).item()\n",
    "\n",
    "            embeddings = get_embeddings_from_decoder(encoder_decoder.decoder).weight\n",
    "            similarities = get_similarities_to_embeddings(\n",
    "                virtual_embs, embeddings\n",
    "            )  # [batch tok vocab]\n",
    "\n",
    "            # print(\"distances.shape\", distances.shape)\n",
    "\n",
    "            # Get top k tokens by encoder output logits\n",
    "            top_k = 10\n",
    "            top_values, top_indices = torch.topk(\n",
    "                similarities[0], k=top_k, dim=-1\n",
    "            )  # [batch tok]\n",
    "\n",
    "            print(top_indices)\n",
    "            print(top_indices.shape)\n",
    "\n",
    "            print(\"top_values.shape\", top_values.shape)\n",
    "\n",
    "            # Decode tokens for display\n",
    "            sample_decoded = tokenizer.decode(sample_tokens[0])\n",
    "\n",
    "            # Display results\n",
    "            with sample_output:\n",
    "                sample_output.clear_output(wait=True)\n",
    "                print(f\"Sample {sample_idx+1}/{batch_size}\")\n",
    "                print(f\"Target prediction loss: {pred_loss:.6f}\")\n",
    "                print(\"\\nTarget tokens:\")\n",
    "                print(sample_decoded, \"\\n\")\n",
    "\n",
    "                prompt_prefix, prompt_suffix = PROMPT_DECODER.split(\"<thought>\")\n",
    "                # Also decode and display the prefix and suffix tokens\n",
    "                prefix_tokens = tokenizer(prompt_prefix, return_tensors=\"pt\").input_ids[\n",
    "                    0\n",
    "                ]\n",
    "                suffix_tokens = tokenizer(prompt_suffix, return_tensors=\"pt\").input_ids[\n",
    "                    0\n",
    "                ]\n",
    "\n",
    "                print(tokenizer.decode(prefix_tokens))\n",
    "\n",
    "                # Prepare data for the tokens table\n",
    "                col_width = 15\n",
    "                headers = [\"Token\"] + [f\"Emb {i}\" for i in range(virtual_embs.shape[1])]\n",
    "\n",
    "                token_rows = []\n",
    "                for k in range(top_k):\n",
    "                    row = [f\"Top {k+1}:\"]\n",
    "                    for j in range(virtual_embs.shape[1]):\n",
    "                        token_id = top_indices[j, k].item()\n",
    "                        token_text = tokenizer.decode([token_id])\n",
    "                        # Replace newlines and tabs for cleaner display\n",
    "                        token_text = token_text.replace(\"\\n\", \"\\\\n\").replace(\n",
    "                            \"\\t\", \"\\\\t\"\n",
    "                        )\n",
    "                        # Truncate to fit in column\n",
    "                        token_display = token_text[: col_width - 2]\n",
    "                        row.append(token_display)\n",
    "                    token_rows.append(row)\n",
    "\n",
    "                # Create and display the token table\n",
    "                token_table = create_table(\n",
    "                    \"\", headers, token_rows, [8] + [col_width] * virtual_embs.shape[1]\n",
    "                )\n",
    "                print(token_table)\n",
    "\n",
    "                # Create table for logit values\n",
    "                logit_rows = []\n",
    "                for k in range(top_k):\n",
    "                    row = [f\"Top {k+1}:\"]\n",
    "                    for j in range(virtual_embs.shape[1]):\n",
    "                        # Format logit value with 5 decimal places\n",
    "                        prob = top_values[j, k].item()\n",
    "                        row.append(f\"{prob:.5f}\")\n",
    "                    logit_rows.append(row)\n",
    "\n",
    "                # Create and display the logits table\n",
    "                logit_table = create_table(\n",
    "                    \"Logit Values:\",\n",
    "                    headers,\n",
    "                    logit_rows,\n",
    "                    [8] + [col_width] * virtual_embs.shape[1],\n",
    "                )\n",
    "                print(logit_table)\n",
    "\n",
    "                print(tokenizer.decode(suffix_tokens))\n",
    "\n",
    "                print(sum(losses) / len(losses))\n",
    "\n",
    "\n",
    "# Interactive sample investigation\n",
    "next_button = widgets.Button(description=\"Next Sample\")\n",
    "next_button.on_click(on_button_click)\n",
    "\n",
    "# Display the button and sample output in separate areas\n",
    "with button_output:\n",
    "    display(next_button)\n",
    "display(button_output)\n",
    "display(sample_output)\n",
    "\n",
    "# Show the first sample\n",
    "if batch_size > 0:\n",
    "    display_sample(current_sample)\n",
    "    current_sample += 1\n",
    "else:\n",
    "    with sample_output:\n",
    "        print(\"No samples in batch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 60\n",
    "\n",
    "sample_tokens = target_generated_tokens[sample_idx : sample_idx + 1].to(\n",
    "    cfg.device, dtype=torch.long\n",
    ")\n",
    "sample_tokens, attention_mask = recode_and_strip(sample_tokens, tokenizer)\n",
    "sample_tokens = sample_tokens.to(cfg.device)\n",
    "attention_mask = attention_mask.to(cfg.device)\n",
    "sample_acts = target_acts[sample_idx : sample_idx + 1].to(cfg.device)\n",
    "\n",
    "print(sample_tokens)\n",
    "print(tokenizer.decode(sample_tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"Bob\"\n",
    "# tokens = tokenizer(text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "# Print each token separately\n",
    "# print(\"Tokens for text:\", text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[44484,   474,   330,   672,  1559,   373,   257,   922,  1048,    13,\n",
      "         14862,   220]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "tensor([[44484,   474,   330,   672,  1559,   373,   257,   922,  1048,    13,\n",
      "         14862,   220]])\n",
      "torch.Size([50257])\n",
      "Top 10 tokens by logit:\n",
      "1. Token: 'Â ', ID: 1849, Logit: -46.7644\n",
      "2. Token: 'iced', ID: 3711, Logit: -47.3270\n",
      "3. Token: 'ich', ID: 488, Logit: -48.3128\n",
      "4. Token: 'ive', ID: 425, Logit: -48.6372\n",
      "5. Token: 'irl', ID: 1901, Logit: -48.7395\n",
      "6. Token: 'ix', ID: 844, Logit: -49.0847\n",
      "7. Token: 'iz', ID: 528, Logit: -49.1540\n",
      "8. Token: 'izzy', ID: 40593, Logit: -49.2239\n",
      "9. Token: 'ike', ID: 522, Logit: -49.2902\n",
      "10. Token: '________', ID: 2602, Logit: -49.3509\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "text = \"Alice jacobson was a good person. Alice \"\n",
    "tokens = tokenizer(text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "print(tokens)\n",
    "print(tokens.input_ids)\n",
    "tokens = torch.cat([torch.tensor([[tokenizer.bos_token_id]]), tokens.input_ids], dim=1)\n",
    "\n",
    "# Get model outputs\n",
    "outputs = model(tokens)\n",
    "logits = outputs.logits\n",
    "\n",
    "# Get the logits for the last token\n",
    "last_token_logits = logits[0, -1, :]\n",
    "print(last_token_logits.shape)\n",
    "\n",
    "# Get the top 3 token indices and their corresponding logits\n",
    "k = 10\n",
    "top_values, top_indices = torch.topk(last_token_logits, k)\n",
    "\n",
    "# Print the top 3 tokens and their logits\n",
    "print(f\"Top {k} tokens by logit:\")\n",
    "for i, (token_id, logit_value) in enumerate(zip(top_indices, top_values)):\n",
    "    token_text = tokenizer.decode([token_id.item()])\n",
    "    print(\n",
    "        f\"{i+1}. Token: '{token_text}', ID: {token_id.item()}, Logit: {logit_value.item():.4f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
